{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Job1:\n",
    "\n",
    "Central Intelligence Agency\n",
    "\n",
    "[link](https://www.cia.gov/careers/opportunities/analytical/political-analyst.html)​"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Job2\n",
    "\n",
    "BAE Systems\n",
    "\n",
    "[link](https://jobs.baesystems.com/global/en/job/BAE1US27800/Intelligence-Analyst-Mid-Level?utm_source=indeed&utm_medium=phenom-feed)​\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlwt        \n",
    "from collections import Counter        \n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "book = xlwt.Workbook() # create a new excel file\n",
    "sheet_test = book.add_sheet('word_count') # add a new sheet\n",
    "i = 0\n",
    "sheet_test.write(i,0,'word') # write the header of the first column\n",
    "sheet_test.write(i,1,'count') # write the header of the second column\n",
    "sheet_test.write(i,2,'ratio') # write the header of the third column\n",
    "\n",
    "with open('job1.txt','r',encoding='utf-8', errors = 'ignore') as text_word: # define the location of your txt file\n",
    "\n",
    "\n",
    "    # convert all the word into lower cases\n",
    "    # filter out stop words\n",
    "\n",
    "    word_list = [i for i in text_word.read().lower().split() if i not in stop]\n",
    "    word_total = word_list.__len__()\n",
    "\n",
    "     \n",
    "    count_result =  Counter(word_list)\n",
    "    for result in count_result.most_common(10):\n",
    "        i = i+1 \n",
    "        sheet_test.write(i,0,result[0])\n",
    "        sheet_test.write(i,1,result[1])\n",
    "        sheet_test.write(i,2,(result[1]/word_total))\n",
    "    \n",
    "book.save('job1.xls')# define the location of your excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlwt        \n",
    "from collections import Counter        \n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "book = xlwt.Workbook() # create a new excel file\n",
    "sheet_test = book.add_sheet('word_count') # add a new sheet\n",
    "i = 0\n",
    "sheet_test.write(i,0,'word') # write the header of the first column\n",
    "sheet_test.write(i,1,'count') # write the header of the second column\n",
    "sheet_test.write(i,2,'ratio') # write the header of the third column\n",
    "\n",
    "with open('job2.txt','r',encoding='utf-8', errors = 'ignore') as text_word: # define the location of your txt file\n",
    "\n",
    "\n",
    "    # convert all the word into lower cases\n",
    "    # filter out stop words\n",
    "\n",
    "    word_list = [i for i in text_word.read().lower().split() if i not in stop]\n",
    "    word_total = word_list.__len__()\n",
    "\n",
    "     \n",
    "    count_result =  Counter(word_list)\n",
    "    for result in count_result.most_common(10):\n",
    "        i = i+1 \n",
    "        sheet_test.write(i,0,result[0])\n",
    "        sheet_test.write(i,1,result[1])\n",
    "        sheet_test.write(i,2,(result[1]/word_total))\n",
    "    \n",
    "book.save('job2.xls')# define the location of your excel file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job 1 CIA\n",
    "<img src = \"job1cloud.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job 2 BAE\n",
    "<img src = \"job2cloud.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'must', 'successfully', 'considered', 'last', 'residency', 'action:', 'assessments', '(competitive', 'making', 'Ability', 'region', 'here', 'studies:', 'environment', 'analytic', 'area', 'stability,', 'investigation', 'deepen', 'social', 'A', '12', 'happen.', 'Learn', 'following', 'career', \"master's\", 'tradecraft', 'Minimum', 'more', 'verbal', 'Awareness', 'Life', 'policy,', 'context', 'use', 'As', 'motivations,', 'capability', 'text', 'opportunities', '4-point', 'GPAs)', 'Proficiency', 'governments', \"isn't\", 'relocation', 'scale', 'Washington,', 'environment.', 'related', 'functional', 'insights', 'write', 'history,', 'thinking', 'affairs', 'medical', 'metro', 'assignments', 'suitable', 'Political', 'travel,', 'Demonstrated', 'unique', 'culture,', 'processes,', 'thorough', 'CIA', 'See', 'delivering', 'forefront', 'concise', 'Analysis', 'Science', 'candidates', 'decisions.', 'comprehensive', 'offers', 'degree', 'Foreign', 'critical', 'solving', 'substantive', 'issue', \"We're\", 'DA', 'they', 'offices', 'at', 'So', 'one', 'International', 'training', 'throughout', 'Research', 'polygraph', 'citizens', 'clear,', 'job,', 'least', 'Within', 'background', 'Opportunities', 'senior', 'you', 'society,', 'mindset', 'inform', 'timely,', 'carefully', 'complete:', 'how', 'just', 'Government.', 'DC', '3.0', \"actors'\", 'regular', 'incomplete', 'during', 'examine', 'national', 'security.', 'presentation', 'Qualifications:', 'require', 'GPA', 'typically', 'psychological', 'interests', 'politics,', 'these', 'processing.', 'affect', 'required', 'Agency', 'CIA,', 'In', 'prior', 'domestic', 'fields', 'benefits', 'world-altering', 'entities.', 'Desired', 'expertise,', 'Deep', 'ideologies', 'working', 'citizenship', 'lifestyle.', 'provide', 'addition', 'interview', 'exam', '(dual-national', 'policymakers', 'area.', 'all-source', 'studies', 'will', 'Offices', 'Directorate', 'helps', 'exciting', 'team', 'To', 'goals', 'employment,', 'US', 'requires', 'policy', 'illegal', 'accurate', 'contradictory', 'All', 'dynamic', 'language', 'Your', '(DA),', 'transformed', 'pertinent', 'sometimes', 'exist', 'writing', 'objective', 'Strong', 'regional', 'ago', 'evaluated', 'events', 'producing', 'foreign', 'drug', 'drugs', \"it's\", 'Interest', 'within', 'problem', 'Affairs', 'elements', 'eligible).', 'months', 'decision', 'values,', 'training,', 'positions', 'travel', 'international', 'Analysis.', 'applicants', 'months.', 'package,', 'used', 'higher'}\n",
      "{'support;', 'Education', 'Required', 'Experience', 'ratios;', 'duties', 'projects', 'requirements;', 'principles', 'Security', 'demonstrate', 'advanced', 'Knowing', 'findings', 'personnel', 'search;', 'excellent', 'functions,', 'Virginia,', 'treatment', 'Typical', 'defeat', 'conduct', 'draws', 'applying', 'summaries,', 'questionnaires;', 'threats', 'push', 'organizations,', 'Thats', 'incoming', 'administrative', 'accepted', 'filing', 'communication,', 'Provides', 'evaluates', 'editing', 'routing', 'authority,', 'common', 'customer', 'files', 'obtain', 'Security,', 'development,', 'data,', 'procedures', 'flowcharting', 'processes;', 'designs', 'estimates', 'guidance', 'format(s)', 'as:', 'IT', 'limited', 'systems,', 'charting;', 'documents,', 'identifying', 'discuss', 'intelligence,', 'organization,', 'do', 'documentation', 'methodology', '2', 'analysis,', 'manuals', 'Accesses', 'understanding', 'interviews', 'research', 'two', 'methods', 'which', 'staff', 'maintenance', 'include,', 'standard', 'defense,', 'situations,', 'job', 'important', 'past', 'automated', 'procedural', 'workload', 'us', 'operations', 'conditions,', 'minimum', 'reports', 'such', 'literature', 'products', 'required.', 'task', 'planning;', 'threat', 'complex', 'perform', 'identified', 'nature.', 'covering', 'measurement;', 'consistently', 'recognize,', 'current', 'customer,', 'pride', 'manage', 'modes,', 'tailored', 'years', 'conducting', '&', 'military', 'channels', 'technical', 'communications', 'measures.', 'but', 'areas', 'enables', 'briefings', 'design;', 'McLean,', 'guidelines', 'similar', 'U.S.', 'are', 'procedures.', 'storage', 'calculation', 'conclusions,', 'records.', 'upon', 'presentations', 'practices', 'everything', 'trends;', 'integration,', 'government', 'Degree', 'space', 'cyber', 'determining', 'theory', 'specialized', 'dofrom', 'interest', 'technologies', 'identification,', 'inspires', 'delivers', 'performance', 'equivalent', 'supervisors', 'based', 'deviations,', 'an', 'susceptible', 'information,', 'conditions', 'structuring;', 'assigned.', 'systems', 'following:', 'well', 'Systems', 'ourselves', 'Develops', 'missions', 'productivity', 'customer;', 'databases', 'consideration,', 'organizational', 'BAE', 'dedication', 'apply', 'specified', 'direction,', 'received.', 'employees', 'recommendations.', 'Shall', 'readily', 'delegation', 'Reviews', 'Bachelors', 'relevant', 'About', 'performs', 'new', 'programs;', 'standards,', 'pertaining', 'may', 'methods;', 'appropriate', 'correspondence,', 'collection', 'with', 'analytical', 'responsibility,', 'Inspired', 'Our', 'shows', 'probabilities', 'reports,', 'operating', 'levels.', 'appear', 'services.', 'Systems.', \"customer's\", '(2)', 'qualitative', 'factual', 'graphing;', 'significance', 'quantitative', 'able', 'production', 'downloading', 'techniques', 'resolution', 'purpose', 'statistical', 'responsibilities', 'missions,', 'customers.', 'Typically', 'problems', 'Work.', 'development', 'Presents', 'Intelligence', 'designated', 'medium,', 'we', 'appropriately', 'Establishes', 'evaluative', 'means,', 'plans,', 'Skills', 'administration', 'solutions', 'deal', 'knowledge', 'observable'}\n"
     ]
    }
   ],
   "source": [
    "with open('job1.txt','r',encoding='utf-8', errors= 'ignore') as job1:\n",
    "    with open ('job2.txt','r',encoding='utf-8', errors = 'ignore') as job2:\n",
    "        job1_str =job1.read()\n",
    "        job2_str =job2.read()\n",
    "        \n",
    "        job1_set= set(job1_str.split())\n",
    "        job2_set= set(job2_str.split())\n",
    "        \n",
    "        print (job1_set.difference(job2_set))\n",
    "        print (job2_set.difference(job1_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "with open('job1.txt','r',encoding='utf-8', errors= 'ignore') as job1:\n",
    "    with open ('job2.txt','r',encoding='utf-8', errors = 'ignore') as job2:\n",
    "        job1_str =job1.read()\n",
    "        job2_str =job2.read()\n",
    "        print(fuzz.token_sort_ratio(job1_str,job2_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
